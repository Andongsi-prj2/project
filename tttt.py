import torch
from PIL import Image
import torchvision.transforms as transforms

# 1. ëª¨ë¸ ë¡œë”© (ì „ì²´ ëª¨ë¸ í¬í•¨ëœ .pt íŒŒì¼)
model = torch.load("resnet18_full.pt", map_location="cpu", weights_only=False)  # ğŸ”¥ êµ¬ì¡° + ê°€ì¤‘ì¹˜ ëª¨ë‘ í¬í•¨
model.eval()

# 2. ì „ì²˜ë¦¬ ì •ì˜ (ResNet18 ê¸°ì¤€ Normalize í¬í•¨)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],  # âœ… ë°˜ë“œì‹œ í¬í•¨
                         [0.229, 0.224, 0.225])
])

# 3. í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ
image_path = "decoded_images/KEMP_IMG_DATA_2.png"  # ìŠ¬ë˜ì‹œ ì‚¬ìš© ê¶Œì¥
image = Image.open(image_path).convert("RGB")

# 4. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° í…ì„œ ë³€í™˜
image_tensor = transform(image).unsqueeze(0)  # [1, 3, 224, 224]

# 5. ëª¨ë¸ ì¶”ë¡ 
with torch.no_grad():
    output = model(image_tensor)
    predicted_class = torch.argmax(output, 1).item()

# 6. ê²°ê³¼ ì¶œë ¥
label_map = {0: 'ë¶ˆëŸ‰', 1: 'ì •ìƒ'}  # ì˜ˆì¸¡ í´ë˜ìŠ¤ ì •ì˜
label = label_map.get(predicted_class, f"ì•Œ ìˆ˜ ì—†ìŒ ({predicted_class})")

print(f"âœ… ì¶”ë¡  ê²°ê³¼: í´ë˜ìŠ¤ {predicted_class} â†’ {label}")
